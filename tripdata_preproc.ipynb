{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fbfdd3b-a49b-46ab-909b-369ff7c34cfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b5152a-5bf0-4763-8696-0c45283939f2",
   "metadata": {},
   "source": [
    "Pull in the raw rides csvs for each month from S3 bucket, and concatenate all months into a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f026fff9-2bfd-457a-ae6b-89ff9334da3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket(\"capitalbikeshare-data\")\n",
    "\n",
    "objs = bucket.objects.filter(Prefix='202')\n",
    "\n",
    "df_rides = []\n",
    "for obj in objs:\n",
    "    if int(obj.key[:6]) >= 202106:\n",
    "        obj_bytes = obj.get()['Body'].read()\n",
    "        with zipfile.ZipFile(io.BytesIO(obj_bytes), \"r\") as temp_zip:\n",
    "            csv_filename = temp_zip.namelist()[0]\n",
    "            with temp_zip.open(csv_filename) as csv_file:\n",
    "                temp_df = pd.read_csv(csv_file, encoding='utf8')\n",
    "                df_rides.append(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6962f66a-fb7b-4460-be11-33430d8e30a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_rides_all = pd.concat(df_rides)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203394d0-727f-42e6-b618-c25be2300758",
   "metadata": {},
   "source": [
    "Clean up, and engineer some logical and datetime features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d192e603-95ca-4099-aaba-6ad603a15abe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_cols = ['started_at', 'ended_at']\n",
    "df_rides_all[time_cols] = df_rides_all[time_cols].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10119143-7809-471c-88b5-b869278b3508",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove some rides with missing end locations\n",
    "missing_end_location = df_rides_all.loc[(df_rides_all['end_lat'].isna()) | (df_rides_all['end_lat']==0) | (df_rides_all['end_lng']==0)]\n",
    "rides_clean = df_rides_all.drop(missing_end_location.index, axis=0)\n",
    "\n",
    "# drop ride ID\n",
    "rides_clean = rides_clean.drop('ride_id', axis=1)\n",
    "\n",
    "rides_clean['is_ebike'] = rides_clean['rideable_type'] == 'electric_bike'\n",
    "rides_clean['is_member'] = rides_clean['member_casual'] == 'member'\n",
    "rides_clean['start_docked'] = ~rides_clean['start_station_id'].isna()\n",
    "rides_clean['end_docked'] = ~rides_clean['end_station_id'].isna()\n",
    "\n",
    "rides_clean.loc[:, 'start_hour'] = rides_clean.loc[:,'started_at'].dt.floor(\"H\")\n",
    "rides_clean.loc[:, 'end_hour'] = rides_clean.loc[:, 'ended_at'].dt.floor(\"H\")\n",
    "rides_clean.loc[:, 'duration_mins'] = rides_clean['ended_at'] - rides_clean['started_at']\n",
    "rides_clean.loc[:, 'duration_mins'] = np.round(rides_clean.loc[:, 'duration_mins'].dt.total_seconds()/60, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3327725-85b7-4e37-b09e-18b8e8b08e5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rides_clean.to_csv(\"data/df_rides.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b970ac-4a6a-43fd-8417-c09114959e23",
   "metadata": {},
   "source": [
    "Drop all rides with missing start or end location. These are a small fraction (5-10% of all rides)\n",
    "Looking at the dataframe, it seems to be almost exclusively the e-bikes, because these are dockless. Would be interesting to look at in another context, but since the resolution of the start and end locations for these is clearly different (they are simply assigned to a grid location), it's easier to exclude them from this project.\n",
    "Given the dockless nature, their rental patterns may be markedly different, and the operational requirements or priorities will also be different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4f4d5c1-551b-4dff-b29e-b66e9d8a3031",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop rides with missing start or end\n",
    "no_stations = (rides_clean['start_station_id'].isna()) | (rides_clean['end_station_id'].isna())\n",
    "rides_clean = rides_clean.loc[~no_stations, :]\n",
    "\n",
    "train_cutoff = pd.Timestamp(2023, 6, 1)\n",
    "rides_train = rides_clean.loc[(rides_clean['started_at'] <= train_cutoff)\n",
    "                              & (rides_clean['ended_at'] <= train_cutoff), :]\n",
    "rides_test = rides_clean.loc[rides_clean['started_at'] > train_cutoff, :]\n",
    "\n",
    "# save train and test raw datasets\n",
    "rides_train.to_csv(\"data/rides_train_clean.csv\", index=False)\n",
    "rides_test.to_csv(\"data/rides_test_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928e1fc8-9382-4b97-a06f-2f9b12489257",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "164cd15b-e12b-4d64-87af-d5a79240da12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def haversine_distance(X, Y):\n",
    "    \"\"\"\n",
    "    Calculate the Haversine distance between two points given their longitude and latitude coordinates.\n",
    "    X and Y should be provided as nx2 arrays, with lon,lat columns\n",
    "    \"\"\"\n",
    "    X = np.radians(X)\n",
    "    Y = np.radians(Y)\n",
    "\n",
    "    dlon = Y[:, 0] - X[:, 0]\n",
    "    dlat = Y[:, 1] - X[:, 1]\n",
    "\n",
    "    a = np.sin(dlat / 2) ** 2 + np.cos(X[:, 1]) * np.cos(Y[:, 1]) * np.sin(dlon / 2) ** 2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    #distance = c / 6371  # Radius of the Earth in kilometers\n",
    "    distance = c / 3958.8  # Radius of the Earth in miles\n",
    "\n",
    "    return distance\n",
    "\n",
    "# calculate the distance of each ride, in great-circle\n",
    "start_locs = rides_clean[['start_lng', 'start_lat']].values\n",
    "end_locs = rides_clean[['end_lng', 'end_lat']].values\n",
    "rides_clean['ride_hav_dist_mi'] = haversine_distance(start_locs, end_locs)  # convert to miles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eb173a-7018-4684-a9fe-613b54085061",
   "metadata": {},
   "source": [
    "Use boto3 to upload the train and test csv files to AWS S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd7b62e4-1068-46bd-a8b8-5c09deeb9133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "local_file_path = 'data/rides_train.csv'\n",
    "s3_bucket = \"sagemaker-cabi-data\"\n",
    "s3_key = 'rides_train.csv'\n",
    "\n",
    "# Upload the file to S3\n",
    "s3.upload_file(Filename=local_file_path, Bucket=s3_bucket, Key=s3_key)\n",
    "\n",
    "local_file_path = 'data/rides_test.csv'\n",
    "s3_bucket = \"cabi-train-test\"\n",
    "s3_key = 'rides_test.csv'\n",
    "\n",
    "# Upload the file to S3\n",
    "s3.upload_file(Filename=local_file_path, Bucket=s3_bucket, Key=s3_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e02621d2-1f70-4c7c-87f4-58a29f5fd2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "local_file_path = 'model_artefacts/darts_xgb_gzip.gz'\n",
    "s3_bucket = \"cabi-model-artefacts\"\n",
    "s3_key = 'darts_xgb_gzip.gz'\n",
    "\n",
    "s3.upload_file(Filename=local_file_path, Bucket=s3_bucket, Key=s3_key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scipy:Python",
   "language": "python",
   "name": "conda-env-scipy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
